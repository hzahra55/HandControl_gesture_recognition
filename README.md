# HandControl_gesture_recognition


This project presents a hand gesture recognition system designed to control YouTube videos using machine learning. By using the Jester dataset and training a ResNet-101 model, the system can interpret ten distinct gestures in real-time through the webcam corresponding to various video control functionalities, such as play, pause, forward, rewind, and fullscreen. Depending on the hand gestures predicted, the corresponding keystrokes (keyboard shortcuts) will be sent to trigger actions on a computer. With a real-world accuracy of 75%, this project demonstrates the potential for touchless human-computer interaction (HCI) and sets the groundwork for further advancements.

